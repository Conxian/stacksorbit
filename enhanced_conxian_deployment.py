#!/usr/bin/env python3
"""
Enhanced Conxian Deployment Script with CLI Integration
Provides comprehensive deployment and monitoring capabilities for the Conxian protocol
"""

import os
import sys
import json
import time
import subprocess
import requests
import yaml
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import argparse
from dotenv import dotenv_values
from stacksorbit_secrets import SECRET_KEYS
from deployment_monitor import DeploymentMonitor

# Force UTF-8 encoding for stdout on Windows
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding="utf-8")

# Enhanced imports for monitoring
try:
    import psutil

    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

try:
    import colorama
    from colorama import Fore, Style

    colorama.init()
    COLORAMA_AVAILABLE = True
except ImportError:
    COLORAMA_AVAILABLE = False


class EnhancedConfigManager:
    """Enhanced configuration manager with persistence and validation"""

    def __init__(self, config_path: str = ".env"):
        self.config_path = Path(config_path)
        self.config = {}
        self.deployment_history = []

    def load_config(self) -> Dict:
        """Load configuration from .env file, prioritizing environment variables."""
        if not self.config_path.exists():
            self._create_default_config()

        # Load variables from the .env file first.
        file_config = dotenv_values(dotenv_path=self.config_path)

        # Sentinel Security Enhancement: Check for secrets in the file.
        for key in SECRET_KEYS:
            if file_config.get(key) and file_config[key] not in (
                "",
                "your_private_key_here",
            ):
                error_message = (
                    f"üõ°Ô∏è Sentinel Security Error: Secret key '{key}' found in .env file.\n"
                    "   Storing secrets in plaintext files is a critical security risk and is not permitted.\n"
                    "   For your protection, please move this secret to an environment variable and remove it from the .env file.\n"
                    f"   Example: export {key}='your_secret_value_here'"
                )
                raise ValueError(error_message)

        # Create a combined configuration, prioritizing environment variables.
        # The security check above ensures no secrets are loaded from the file.
        # This logic correctly allows ALL config values (including non-secrets)
        # to be overridden by environment variables.
        combined_config = {}
        combined_config.update(file_config)
        combined_config.update(
            {
                k: v
                for k, v in os.environ.items()
                if k in file_config or k in SECRET_KEYS
            }
        )

        self.config = combined_config

        # Store the config path for the deployer to use
        self.config["CONFIG_PATH"] = str(self.config_path)

        # Normalize keys for compatibility
        if (
            "STACKS_DEPLOYER_PRIVKEY" in self.config
            and "DEPLOYER_PRIVKEY" not in self.config
        ):
            self.config["DEPLOYER_PRIVKEY"] = self.config["STACKS_DEPLOYER_PRIVKEY"]
        elif "STACKS_PRIVKEY" in self.config and "DEPLOYER_PRIVKEY" not in self.config:
            self.config["DEPLOYER_PRIVKEY"] = self.config["STACKS_PRIVKEY"]

        return self.config

    def _create_default_config(self):
        """Create default configuration file"""
        default_config = """# Enhanced StacksOrbit Configuration for Conxian
# Generated by Enhanced CLI

# Required Variables
DEPLOYER_PRIVKEY=your_private_key_here
SYSTEM_ADDRESS=your_stacks_address_here
NETWORK=testnet

# Optional Variables (Recommended)
HIRO_API_KEY=your_hiro_api_key
CORE_API_URL=https://api.testnet.hiro.so
STACKS_API_BASE=https://api.testnet.hiro.so

# Deployment Configuration
DEPLOYMENT_MODE=full
BATCH_SIZE=5
PARALLEL_DEPLOY=false
CONTRACT_FILTER=

# Monitoring Configuration
MONITORING_ENABLED=true
LOG_LEVEL=INFO
SAVE_LOGS=true

# Security
VALIDATE_TRANSACTIONS=true
CONFIRMATION_TIMEOUT=300
"""

        self.config_path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.config_path, "w") as f:
            f.write(default_config)

    def save_config(self, config: Dict):
        """Save configuration to file"""
        with open(self.config_path, "w") as f:
            for key, value in config.items():
                f.write(f"{key}={value}\n")

    def validate_config(self) -> Tuple[bool, List[str]]:
        """Validate configuration and return (is_valid, errors)"""
        errors = []

        required = ["DEPLOYER_PRIVKEY", "SYSTEM_ADDRESS", "NETWORK"]
        for req in required:
            if req not in self.config or not self.config[req]:
                errors.append(f"Missing required configuration: {req}")

        # Validate private key format
        if "DEPLOYER_PRIVKEY" in self.config:
            priv = self.config["DEPLOYER_PRIVKEY"]
            if priv.strip().lower() == "your_private_key_here":
                errors.append("DEPLOYER_PRIVKEY uses insecure placeholder value")
            elif not self._validate_private_key(priv):
                errors.append("Invalid DEPLOYER_PRIVKEY format")

        # Validate address format
        if "SYSTEM_ADDRESS" in self.config:
            addr = self.config["SYSTEM_ADDRESS"]
            net = self.config.get("NETWORK")
            if not self._validate_address(addr, net):
                errors.append("Invalid SYSTEM_ADDRESS format")

        # Validate network
        if "NETWORK" in self.config:
            if self.config["NETWORK"] not in ["devnet", "testnet", "mainnet"]:
                errors.append("Invalid NETWORK. Must be devnet, testnet, or mainnet")

        return len(errors) == 0, errors

    def _validate_private_key(self, privkey: str) -> bool:
        """Validate private key format"""
        if not privkey or not isinstance(privkey, str):
            return False
        pk = privkey.strip()
        if pk.lower() == "your_private_key_here":
            return False
        if len(pk) not in (64, 66):
            return False
        # Hex-only characters
        for c in pk:
            if c not in "0123456789abcdefABCDEF":
                return False
        return True

    def _validate_address(self, address: str, network: Optional[str] = None) -> bool:
        """Validate Stacks address format by network and charset"""
        if not address or not isinstance(address, str):
            return False
        addr = address.strip().upper()
        # Prefix rules: SP for mainnet, ST for testnet/devnet
        if network == "mainnet":
            if not addr.startswith("SP"):
                return False
        else:
            if not addr.startswith("ST"):
                return False
        # C32 allowed charset (I, L, O, U are excluded)
        allowed = set("0123456789ABCDEFGHJKMNPQRSTVWXYZ")
        body = addr[2:]
        if len(addr) != 41:
            return False
        return all(ch in allowed for ch in body)


class EnhancedConxianDeployer:
    """Enhanced Conxian deployer with full CLI integration"""

    def __init__(
        self,
        config: Dict,
        verbose: bool = False,
        run_npm_tests: bool = False,
        npm_test_script: str = "test",
        clarinet_check_timeout: int = 300,
        monitor: Optional[DeploymentMonitor] = None,
    ):
        self.config = config
        self.verbose = verbose
        self.run_npm_tests = run_npm_tests
        self.npm_test_script = npm_test_script
        self.clarinet_check_timeout = clarinet_check_timeout
        self.pre_check_results: Dict[str, bool] = {}
        # Bolt ‚ö°: Use a shared monitor instance to leverage caching
        # If no monitor is provided, create a new one.
        self.monitor = monitor or DeploymentMonitor(
            config.get("NETWORK", "testnet"), config
        )
        self.contract_categories = self._load_contract_categories()

    def _load_contract_categories(self) -> Dict:
        """Load contract categories from configuration (Generic + Conxian)"""
        return {
            # Generic Categories
            "traits": ["trait", "interface", "standard", "sip-"],
            "libs": ["utils", "lib", "math", "constant", "err"],
            "tokens": ["token", "ft", "nft", "coin"],
            "defi": [
                "swap",
                "pool",
                "dex",
                "vault",
                "pair",
                "liquidity",
                "staking",
                "farm",
            ],
            "oracle": ["oracle", "price", "feed"],
            "dao": ["governance", "dao", "proposal", "voting", "timelock"],
            "storage": ["store", "registry", "db", "list"],
            # Conxian Specific (kept for backward compatibility)
            "core": ["all-traits", "utils-encoding", "utils-utils", "lib-error-codes"],
            "conxian_tokens": [
                "cxd-token",
                "cxlp-token",
                "cxvg-token",
                "cxtr-token",
                "cxs-token",
            ],
            "conxian_governance": [
                "governance-token",
                "proposal-engine",
                "timelock-controller",
            ],
            "conxian_dex": [
                "dex-factory",
                "dex-router",
                "dex-pool",
                "dex-vault",
                "fee-manager",
            ],
            "conxian_dimensional": [
                "dim-registry",
                "dim-metrics",
                "position-nft",
                "dimensional-core",
            ],
            "conxian_oracle": ["oracle-aggregator", "btc-adapter"],
            "conxian_security": ["circuit-breaker", "pausable", "mev-protector"],
            "conxian_monitoring": ["analytics-aggregator", "monitoring-dashboard"],
        }

    def _get_project_dir(self) -> Path:
        if self.config.get("PROJECT_ROOT"):
            return Path(self.config.get("PROJECT_ROOT"))

        config_path = Path(self.config.get("CONFIG_PATH", ".env"))
        return config_path.parent

    def run_pre_checks(self) -> bool:
        """Run comprehensive pre-deployment checks"""
        print(f"\n[INFO] Running Pre-Deployment Checks\n")

        checks = [
            ("Environment", self._check_environment),
            ("Network", self._check_network),
            ("Compilation", self._check_compilation),
        ]

        if self.run_npm_tests:
            checks.append(("NPM Tests", self._check_npm_tests))

        checks.extend(
            [
                ("Account Balance", self._check_balance),
                ("Deployment Mode", self._check_deployment_mode),
                ("System Alignment", self._check_system_alignment),
            ]
        )

        all_passed = True
        self.pre_check_results = {}
        for check_name, check_func in checks:
            try:
                passed = bool(check_func())
                self.pre_check_results[check_name] = passed
                if not passed:
                    all_passed = False
            except Exception as e:
                self.pre_check_results[check_name] = False
                print(f"[ERROR] {check_name} check failed: {e}")
                all_passed = False

        print(
            f"\n{'[SUCCESS]' if all_passed else '[ERROR]'} Overall Status: {'READY' if all_passed else 'ISSUES FOUND'}"
        )
        return all_passed

    def _check_environment(self) -> bool:
        """Check environment configuration"""
        print("Checking environment variables...")

        required = ["DEPLOYER_PRIVKEY", "SYSTEM_ADDRESS", "NETWORK"]
        missing = [req for req in required if not self.config.get(req)]

        if missing:
            print(f"[ERROR] Missing required variables: {', '.join(missing)}")
            return False

        print(f"[SUCCESS] DEPLOYER_PRIVKEY: <set>")
        print(f"[SUCCESS] SYSTEM_ADDRESS: <set>")
        print(f"[SUCCESS] NETWORK: <set>")
        return True

    def _check_network(self) -> bool:
        """Check network connectivity"""
        print("Checking network connectivity...")

        api_status = self.monitor.check_api_status()
        if api_status["status"] == "online":
            print(f"[SUCCESS] Connected to {api_status['network_id']}")
            print(f"[SUCCESS] Block height: {api_status['block_height']}")
            return True
        else:
            print(
                f"[ERROR] Network check failed: {api_status.get('error', 'Unknown error')}"
            )
            return False

    def _check_compilation(self) -> bool:
        """Check contract compilation"""
        print("Checking contract compilation...")

        project_dir = self._get_project_dir()
        timeout = int(self.clarinet_check_timeout)

        try:
            stdin_input = "y\n" * 10
            result = subprocess.run(
                ["clarinet", "check"],
                cwd=str(project_dir),
                capture_output=True,
                text=True,
                input=stdin_input,
                timeout=timeout,
            )
            output = ((result.stdout or "") + (result.stderr or "")).strip()

            if result.returncode == 0:
                print("[SUCCESS] All contracts compile successfully")
                return True

            print("[ERROR] Compilation issues detected")
            if output:
                if self.verbose:
                    print(output)
                else:
                    lines = output.splitlines()
                    tail = "\n".join(lines[-20:])
                    print(tail)
            return False

        except subprocess.TimeoutExpired as e:
            print(f"[ERROR] Clarinet check timed out after {timeout} seconds")
            if self.verbose:
                out = ((e.stdout or "") + (e.stderr or "")).strip()
                if out:
                    print(out)
            return False
        except FileNotFoundError:
            print("[ERROR] Clarinet not found (is it installed and on PATH?)")
            return False
        except Exception as e:
            print(f"[ERROR] Could not run compilation check: {e}")
            return False

    def _check_npm_tests(self) -> bool:
        """Run npm tests for the project"""
        print("Running npm tests...")

        project_dir = self._get_project_dir()
        package_json = project_dir / "package.json"
        if not package_json.exists():
            print("[INFO] package.json not found - skipping npm tests")
            return True

        script = self.npm_test_script or "test"
        if script == "test":
            command = ["npm", "test"]
        else:
            command = ["npm", "run", script]

        timeout = int(self.config.get("NPM_TEST_TIMEOUT", 1800))

        try:
            result = subprocess.run(
                command,
                cwd=str(project_dir),
                capture_output=True,
                text=True,
                timeout=timeout,
            )

            if result.returncode == 0:
                print(f"[SUCCESS] npm tests passed (script: {script})")
                return True

            print(f"[ERROR] npm tests failed (script: {script})")
            output = ((result.stdout or "") + (result.stderr or "")).strip()
            if output:
                if self.verbose:
                    print(output)
                else:
                    lines = output.splitlines()
                    tail = "\n".join(lines[-40:])
                    print(tail)
            return False

        except subprocess.TimeoutExpired:
            print(
                f"[ERROR] npm tests timed out after {timeout} seconds (script: {script})"
            )
            return False
        except FileNotFoundError:
            print("[ERROR] npm not found (is Node.js installed and on PATH?)")
            return False
        except Exception as e:
            print(f"[ERROR] Could not run npm tests: {e}")
            return False

    def _check_balance(self) -> bool:
        """Check account balance"""
        print("Checking account balance...")

        account_info = self.monitor.get_account_info(self.config["SYSTEM_ADDRESS"])
        if account_info:
            balance_raw = account_info.get("balance", 0)
            balance = (
                int(balance_raw, 16)
                if isinstance(balance_raw, str) and balance_raw.startswith("0x")
                else int(balance_raw)
            ) / 1000000  # Convert to STX
            min_balance = 10  # Minimum 10 STX for deployment

            print(f"[SUCCESS] Current balance: {balance} STX")
            if balance < min_balance:
                print(
                    f"[WARNING] Low balance: {balance} STX (minimum {min_balance} STX recommended)"
                )
                return False
            return True
        else:
            print("[ERROR] Could not check balance")
            return False

    def _check_deployment_mode(self) -> bool:
        """Check deployment mode"""
        print("Checking deployment mode...")

        account_info = self.monitor.get_account_info(self.config["SYSTEM_ADDRESS"])
        if account_info:
            nonce_raw = account_info.get("nonce", 0)
            nonce = (
                int(nonce_raw, 16)
                if isinstance(nonce_raw, str) and nonce_raw.startswith("0x")
                else int(nonce_raw)
            )
            if nonce > 0:
                print(f"[INFO] Upgrade mode (nonce: {nonce})")
                self.config["DEPLOYMENT_MODE"] = "upgrade"
            else:
                print("[INFO] Full deployment mode")
                self.config["DEPLOYMENT_MODE"] = "full"
        else:
            print("[INFO] Assuming full deployment mode")
            self.config["DEPLOYMENT_MODE"] = "full"

        return True

    def _check_system_alignment(self) -> bool:
        """Check system alignment - deployed vs expected contracts"""
        print("Checking system alignment...")

        try:
            # Get expected contracts
            expected_contracts = self._get_deployment_list()
            expected_names = {c["name"] for c in expected_contracts}

            # Get currently deployed contracts
            account_info = self.monitor.get_account_info(self.config["SYSTEM_ADDRESS"])
            if not account_info:
                print("[WARNING] Could not check system alignment - no account info")
                return True

            # Get deployed contracts from the account
            deployed_contracts = self._get_deployed_contracts()
            deployed_names = {c["name"] for c in deployed_contracts}

            # Analyze alignment
            missing_contracts = expected_names - deployed_names
            extra_contracts = deployed_names - expected_names

            # Report alignment status
            if not missing_contracts and not extra_contracts:
                print(
                    f"[SUCCESS] System alignment perfect - all {len(expected_names)} contracts deployed"
                )
                return True
            else:
                print(f"[INFO] System alignment analysis:")
                print(f"   Expected: {len(expected_names)} contracts")
                print(f"   Deployed: {len(deployed_names)} contracts")

                if missing_contracts:
                    print(f"[WARNING] Missing contracts ({len(missing_contracts)}):")
                    for contract in sorted(missing_contracts):
                        print(f"   - {contract}")

                if extra_contracts:
                    print(f"[INFO] Extra contracts ({len(extra_contracts)}):")
                    for contract in sorted(extra_contracts):
                        print(f"   - {contract}")

                # Store alignment data for deployment decisions
                self.system_alignment = {
                    "expected": expected_names,
                    "deployed": deployed_names,
                    "missing": missing_contracts,
                    "extra": extra_contracts,
                    "aligned": len(missing_contracts) == 0
                    and len(extra_contracts) == 0,
                }

                return True  # Don't fail the check, just report

        except Exception as e:
            print(f"[WARNING] Could not check system alignment: {e}")
            return True

    def _get_deployed_contracts(self) -> List[Dict]:
        """Get list of currently deployed contracts for the account"""
        # This is a placeholder - in a real implementation, this would query
        # the Stacks blockchain to get the list of contracts deployed by this account
        deployed = []

        # Simulate checking deployed contracts
        # In reality, this would use Stacks API or SDK to query contract events
        try:
            # For now, we'll simulate based on deployment history
            history_path = Path("deployment") / "history.json"
            if history_path.exists():
                with open(history_path, "r") as f:
                    history = json.load(f)

                # Get the latest deployment
                if history:
                    latest = history[-1]
                    for contract in latest.get("results", {}).get("successful", []):
                        deployed.append(
                            {
                                "name": contract["name"],
                                "tx_id": contract.get("tx_id", ""),
                                "deployed_at": latest.get("timestamp", ""),
                            }
                        )

        except Exception as e:
            print(f"Warning: Could not read deployment history: {e}")

        return deployed

    def deploy_conxian(
        self, category: Optional[str] = None, dry_run: bool = False
    ) -> Dict:
        """Deploy Conxian contracts with enhanced monitoring"""
        print(f"\n[INFO] Conxian Protocol Deployment")
        print("=" * 60)

        if dry_run:
            return self._dry_run_deployment(category)

        # Get deployment list
        contracts = self._get_deployment_list(category)

        # Apply system alignment if available
        if hasattr(self, "system_alignment") and self.system_alignment:
            if self.system_alignment["missing"]:
                print(
                    f"[INFO] Found {len(self.system_alignment['missing'])} missing contracts from previous deployment"
                )
                print(f"[INFO] Will prioritize missing contracts in deployment")

        if not contracts:
            print("[ERROR] No contracts found to deploy")
            return {"success": False, "error": "No contracts found"}

        print(
            f"[INFO] Deploying {len(contracts)} contracts in {self.config.get('DEPLOYMENT_MODE', 'full')} mode\n"
        )

        results = {"successful": [], "failed": [], "skipped": []}

        # Deploy contracts in dependency order
        for i, contract in enumerate(contracts, 1):
            print(f"\n[{i}/{len(contracts)}] Deploying {contract['name']}...")

            try:
                tx_id = self._deploy_single_contract(contract)
                if tx_id:
                    # Monitor transaction
                    confirmed = self.monitor.wait_for_confirmation(
                        tx_id, int(self.config.get("CONFIRMATION_TIMEOUT", 300))
                    )

                    if confirmed:
                        print(f"[SUCCESS] {contract['name']} deployed successfully")
                        results["successful"].append(
                            {"name": contract["name"], "tx_id": tx_id}
                        )
                    else:
                        print(f"[TIMEOUT] {contract['name']} deployment timed out")
                        results["failed"].append(
                            {"name": contract["name"], "error": "timeout"}
                        )
                else:
                    results["failed"].append(
                        {"name": contract["name"], "error": "deployment failed"}
                    )

            except Exception as e:
                print(f"[ERROR] {contract['name']} failed: {e}")
                results["failed"].append({"name": contract["name"], "error": str(e)})

            # Small delay between deployments
            time.sleep(2)

        # Save deployment results
        self._save_deployment_results(results)

        return results

    def _dry_run_deployment(self, category: Optional[str] = None) -> Dict:
        """Perform dry run of deployment"""
        print(f"\n[INFO] DRY RUN MODE")
        print("=" * 60)

        if getattr(self, "pre_check_results", None):
            failed_checks = [
                name for name, ok in self.pre_check_results.items() if not ok
            ]
            if failed_checks:
                print("[INFO] Pre-Deployment Checks Summary (issues detected):")
                for check_name, ok in self.pre_check_results.items():
                    status = "PASS" if ok else "FAIL"
                    print(f"   {status}: {check_name}")
                print()

        contracts = self._get_deployment_list(category)
        total_gas = 0

        print("[INFO] Deployment Plan:\n")

        # Show system alignment if available
        if hasattr(self, "system_alignment") and self.system_alignment:
            if self.system_alignment["missing"]:
                print(f"[INFO] Missing contracts that will be deployed:")
                for contract in sorted(self.system_alignment["missing"]):
                    if any(contract in c["name"] for c in contracts):
                        print(f"   + {contract}")
                print()

        for i, contract in enumerate(contracts, 1):
            gas_estimate = self._estimate_gas(contract)
            total_gas += gas_estimate

            print(f"{i}. {contract['name']}")
            print(f"   Path: {contract['path']}")
            print(f"   Estimated gas: {gas_estimate} STX")
            print()

        print("[SUMMARY]:")
        print(f"   Total contracts: {len(contracts)}")
        print(f"   Estimated gas: {total_gas} STX")
        print(f"   Deployment mode: {self.config.get('DEPLOYMENT_MODE', 'full')}")
        print(f"   Network: {self.config.get('NETWORK', 'testnet')}")

        return {
            "success": True,
            "dry_run": True,
            "contracts": len(contracts),
            "gas_estimate": total_gas,
        }

    def _get_deployment_list(self, category: Optional[str] = None) -> List[Dict]:
        """Get list of contracts to deploy"""
        contracts = []

        # Get the project directory
        if self.config.get("PROJECT_ROOT"):
            project_dir = Path(self.config.get("PROJECT_ROOT"))
        else:
            config_path = Path(self.config.get("CONFIG_PATH", ".env"))
            project_dir = config_path.parent

        # Try Clarinet.toml first in the project directory
        clarinet_path = project_dir / "Clarinet.toml"
        if clarinet_path.exists():
            contracts = self._parse_clarinet_toml(clarinet_path)
        else:
            # Fallback to directory scan in project directory
            contracts = self._scan_contracts_directory(project_dir)

        # Filter by category if specified
        if category and category in self.contract_categories:
            category_contracts = self.contract_categories[category]
            contracts = [
                c
                for c in contracts
                if any(cat in c["name"] for cat in category_contracts)
            ]

        # Sort by dependency order
        return self._sort_by_dependencies(contracts)

    def _parse_clarinet_toml(self, clarinet_path: Path) -> List[Dict]:
        """Parse contracts from Clarinet.toml with dependencies"""
        contracts = []

        try:
            with open(clarinet_path, "r") as f:
                lines = f.readlines()

            current_contract = None
            current_data = {}

            # Custom simple parser for TOML-like structure (robust enough for Clarinet.toml)
            for line in lines:
                line = line.strip()
                if not line or line.startswith("#"):
                    continue

                # Match [contracts.name]
                if line.startswith("[contracts.") and line.endswith("]"):
                    # Save previous contract
                    if current_contract:
                        current_data["name"] = current_contract
                        current_data["full_path"] = (
                            str(clarinet_path.parent / current_data["path"])
                            if "path" in current_data
                            else ""
                        )
                        contracts.append(current_data)

                    # Start new contract
                    current_contract = line[11:-1]
                    current_data = {"depends_on": []}
                    continue

                # Match key = value
                if "=" in line and current_contract:
                    key, value = [p.strip() for p in line.split("=", 1)]

                    # Handle path
                    if key == "path":
                        current_data["path"] = value.strip("\"'")

                    # Handle depends_on = ["a", "b"]
                    elif key == "depends_on":
                        # Simple array parsing: ["a", "b"] -> [a, b]
                        deps_str = value.strip("[]")
                        if deps_str:
                            deps = [d.strip().strip("\"'") for d in deps_str.split(",")]
                            current_data["depends_on"] = [
                                d for d in deps if d
                            ]  # Filter empty

            # Add last contract
            if current_contract:
                current_data["name"] = current_contract
                current_data["full_path"] = (
                    str(clarinet_path.parent / current_data["path"])
                    if "path" in current_data
                    else ""
                )
                contracts.append(current_data)

        except Exception as e:
            print(f"[WARNING] Could not parse Clarinet.toml fully: {e}")
            # Fallback will handle this if list is empty, or return partial results

        return contracts

    def _scan_contracts_directory(self, project_dir: Path) -> List[Dict]:
        """Scan contracts directory for .clar files"""
        contracts = []
        contracts_dir = project_dir / "contracts"

        if contracts_dir.exists():
            for clar_file in contracts_dir.rglob("*.clar"):
                contract_name = clar_file.stem
                contracts.append(
                    {
                        "name": contract_name,
                        "path": str(clar_file.relative_to(project_dir)),
                        "full_path": str(clar_file),
                    }
                )

        return contracts

    def _sort_by_dependencies(self, contracts: List[Dict]) -> List[Dict]:
        """Sort contracts using topological sort based on dependencies"""

        # Build dependency graph
        contract_map = {c["name"]: c for c in contracts}
        graph = {c["name"]: set() for c in contracts}

        for contract in contracts:
            name = contract["name"]
            # Add explicit dependencies
            for dep in contract.get("depends_on", []):
                if dep in contract_map:
                    graph[name].add(dep)

            # implicit trait dependencies (fallback if not explicit)
            if "trait" in name:
                # Traits usually have no deps or depend on other traits
                pass

        # Topological Sort (Kahn's Algorithm modified for simple DFS)
        visited = set()
        temp_mark = set()
        sorted_list = []

        def visit(n):
            if n in temp_mark:
                # Circular dependency detected, break cycle by just returning
                # (In strict mode we'd raise error, but here we want best-effort)
                print(f"[WARNING] Circular dependency detected involving {n}")
                return
            if n not in visited:
                temp_mark.add(n)
                for m in graph.get(n, []):
                    visit(m)
                temp_mark.remove(n)
                visited.add(n)
                sorted_list.append(n)

        # Visit all nodes
        # Sort keys first to ensure deterministic output for independent nodes
        for name in sorted(graph.keys()):
            if name not in visited:
                visit(name)

        # Result is list of names in dependency order
        # Map back to contract objects
        ordered_contracts = []
        for name in sorted_list:
            if name in contract_map:
                ordered_contracts.append(contract_map[name])

        return ordered_contracts

    def _deploy_single_contract(self, contract: Dict) -> Optional[str]:
        """Deploy a single contract (placeholder - would use Stacks SDK)"""
        # This is a placeholder - in a real implementation, this would use
        # the @stacks/transactions library to create and broadcast deployment transactions

        print(f"Deploying {contract['name']}...")

        # Simulate deployment
        time.sleep(1)

        # Generate fake transaction ID for demonstration
        fake_tx_id = "0x" + "1" * 64

        return fake_tx_id

    def _estimate_gas(self, contract: Dict) -> float:
        """Estimate gas cost for contract deployment"""
        # Base estimation - in reality this would be more sophisticated
        base_gas = 1.0  # 1 STX base
        complexity_multiplier = 1.0

        if "dex" in contract["name"]:
            complexity_multiplier = 2.0
        elif "dimensional" in contract["name"]:
            complexity_multiplier = 1.5
        elif "oracle" in contract["name"]:
            complexity_multiplier = 1.3

        return base_gas * complexity_multiplier

    def _save_deployment_results(self, results: Dict):
        """Save deployment results to file"""
        timestamp = datetime.now().isoformat()
        deployment_data = {
            "timestamp": timestamp,
            "network": self.config.get("NETWORK", "testnet"),
            "deployer": self.config.get("SYSTEM_ADDRESS", ""),
            "results": results,
            "config": {
                "mode": self.config.get("DEPLOYMENT_MODE", "full"),
                "batch_size": self.config.get("BATCH_SIZE", 5),
                "total_contracts": len(results["successful"])
                + len(results["failed"])
                + len(results["skipped"]),
            },
        }

        # Save to deployment history
        history_path = Path("deployment") / "history.json"
        history_path.parent.mkdir(exist_ok=True)

        history = []
        if history_path.exists():
            with open(history_path, "r") as f:
                history = json.load(f)

        history.append(deployment_data)

        with open(history_path, "w") as f:
            json.dump(history, f, indent=2)

        print(f"[INFO] Deployment results saved to {history_path}")


def main():
    """Main CLI function"""
    parser = argparse.ArgumentParser(description="Enhanced Conxian Deployment Tool")
    parser.add_argument("--config", default=".env", help="Configuration file path")
    parser.add_argument(
        "--network", choices=["devnet", "testnet", "mainnet"], default="testnet"
    )
    parser.add_argument(
        "--category",
        choices=[
            "core",
            "tokens",
            "dex",
            "dimensional",
            "oracle",
            "security",
            "monitoring",
            "self-run",
            "self-managed",
        ],
    )
    parser.add_argument("--dry-run", action="store_true", help="Perform dry run")
    parser.add_argument("--verbose", "-v", action="store_true", help="Verbose output")
    parser.add_argument("--batch-size", type=int, default=5, help="Contracts per batch")
    parser.add_argument(
        "--parallel", action="store_true", help="Parallel deployment (experimental)"
    )

    args = parser.parse_args()

    try:
        # Load configuration
        config_manager = EnhancedConfigManager(args.config)
        config = config_manager.load_config()

        # Override network if specified
        if args.network:
            config["NETWORK"] = args.network

        # Validate configuration
        is_valid, errors = config_manager.validate_config()
        if not is_valid:
            print("[ERROR] Configuration validation failed:")
            for error in errors:
                print(f"   - {error}")
            return 1

        # Initialize deployer
        deployer = EnhancedConxianDeployer(config, args.verbose)

        # Run pre-checks unless in dry-run mode
        if not args.dry_run:
            if not deployer.run_pre_checks():
                print(
                    "\n[ERROR] Pre-deployment checks failed. Use --dry-run to continue anyway."
                )
                return 1

        # Execute deployment
        results = deployer.deploy_conxian(category=args.category, dry_run=args.dry_run)

        if args.dry_run:
            print("\n[INFO] Dry run completed successfully")
            return 0

        # Show final results
        print("\n[RESULTS] Final Results:")
        print(f"[SUCCESS] Successful: {len(results['successful'])}")
        print(f"[ERROR] Failed: {len(results['failed'])}")
        print(f"[SKIP] Skipped: {len(results['skipped'])}")

        if results["failed"]:
            print("\n[ERROR] Failed contracts:")
            for failed in results["failed"]:
                print(f"   - {failed['name']}: {failed['error']}")
            return 1

        print("\n[SUCCESS] Deployment completed successfully!")
        print("[INFO] Use monitoring tools to verify all contracts are active")

        return 0

    except KeyboardInterrupt:
        print("\n[STOP] Deployment cancelled by user")
        return 1
    except Exception as e:
        # üõ°Ô∏è Sentinel: Prevent sensitive information disclosure.
        # A generic error message is shown to the user.
        # The detailed exception is only logged in verbose mode.
        print(f"\n[ERROR] An unexpected error occurred during deployment.")
        if args.verbose:
            print(f"    Details: {e}")
            import traceback

            traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
